# ğŸ™ï¸ LiveKit MVP Voice Agent

> **A Production-Ready Bilingual Voice Agent with Premium Audio Processing**
> 
> Transform text conversations into immersive voice experiences with AI-powered speech synthesis, local LLM reasoning, and real-time audio streaming.

<div align="center">

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![LiveKit](https://img.shields.io/badge/LiveKit-WebRTC-green.svg)](https://livekit.io/)
[![ElevenLabs](https://img.shields.io/badge/ElevenLabs-Premium%20TTS-purple.svg)](https://elevenlabs.io/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-orange.svg)](https://ollama.ai/)

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ­ Demo Modes](#-demo-modes) â€¢ [ğŸ”§ How It Works](#-how-it-works) â€¢ [ğŸŒ Languages](#-supported-languages)

</div>

---

## ğŸ¯ What This Agent Does

Transform your conversations into intelligent voice interactions:

```mermaid
graph LR
    A[ğŸ¤ Your Voice] --> B[ğŸ§  AI Processing] --> C[ğŸ”Š AI Response]
    B --> D[ğŸ’¬ Text Chat]
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
```

- **ğŸ™ï¸ Speak naturally** in English or French
- **ğŸ§  Get intelligent responses** from local AI
- **ğŸ”Š Hear high-quality voice replies** via ElevenLabs
- **ğŸ’¬ Switch to text mode** anytime
- **ğŸŒ Bilingual support** for language learning

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.11+** ğŸ
- **Docker Desktop** ğŸ³ (for full voice mode)
- **ElevenLabs API Key** ğŸ”‘ (for premium audio)

### Installation
```bash
git clone <your-repo>
cd LiveKit_MVP_Agent
make setup
```

---

## ğŸ­ Demo Modes

Choose your adventure! Each mode offers a different experience:

### 1. ğŸª **Interactive Voice Demo** 
> **What's happening behind the scenes:** ElevenLabs TTS + Mock conversations + Audio generation

```bash
cd elevenlabs_integration
uv run python voice_demo.py
```

**ğŸ¬ Experience:**
- Choose from 4 interactive options
- Generate real audio files
- Test different voices and languages
- Perfect for exploring TTS capabilities

**ğŸ”§ Tech Stack:**
- âœ… **TTS**: ElevenLabs `eleven_flash_v2_5` (premium quality)
- âœ… **Conversations**: Pre-scripted French learning scenarios
- âœ… **Audio**: Real MP3 generation for testing

---

### 2. ğŸ’¬ **Text Chat Agent**
> **What's happening behind the scenes:** Local LLM processing + Simple text interface

```bash
make talk
```

**ğŸ¬ Experience:**
- Type messages, get AI responses
- Fast and lightweight
- Great for testing conversation logic
- No voice processing overhead

**ğŸ”§ Tech Stack:**
- âœ… **LLM**: Attempts Ollama connection, falls back to simple responses
- âœ… **Interface**: Clean terminal chat
- âœ… **Mode**: Text-only for quick interactions

---

### 3. ğŸ™ï¸ **Full Voice Agent** (Complete Experience)
> **What's happening behind the scenes:** LiveKit WebRTC + Ollama LLM + ElevenLabs Audio + Real-time streaming

```bash
# Start the AI brain first
make start-ollama

# Launch the full voice agent
make run
```

**ğŸ¬ Experience:**
- Real-time voice conversations
- WebRTC audio streaming
- Complete AI pipeline
- Production-ready setup

**ğŸ”§ Tech Stack:**
- âœ… **STT**: faster-whisper (local speech recognition)
- âœ… **LLM**: Ollama with llama3.1:8b (local AI reasoning)
- âœ… **TTS**: ElevenLabs premium synthesis
- âœ… **Streaming**: LiveKit WebRTC for real-time audio

---

### 4. ğŸ§ª **ElevenLabs Testing Suite**
> **What's happening behind the scenes:** API testing + Configuration validation + Audio generation

```bash
make test-elevenlabs
```

**ğŸ¬ Experience:**
- Validate your API key
- Test audio generation
- Check configuration
- Generate sample audio files

**ğŸ”§ Tech Stack:**
- âœ… **API**: Direct ElevenLabs testing
- âœ… **Config**: Environment variable validation
- âœ… **Audio**: Sample generation and playback

---

## ğŸ”§ How It Works Under the Hood

### ğŸ¤ **Speech-to-Text (STT) Pipeline**

```mermaid
flowchart TD
    A[ğŸ¤ Your Voice] --> B[ğŸ“Š Audio Capture]
    B --> C[ğŸ”„ Audio Preprocessing]
    C --> D{STT Engine}
    D -->|Premium| E[ğŸ† ElevenLabs Scribe]
    D -->|Local| F[âš¡ faster-whisper]
    E --> G[ğŸ“ Transcribed Text]
    F --> G
    G --> H[ğŸ§  Language Detection]
    H --> I[âœ¨ Text Processing]
    
    style A fill:#e1f5fe
    style E fill:#f3e5f5
    style F fill:#e8f5e8
    style G fill:#fff3e0
```

**What happens:**
1. **ğŸ¤ Audio Capture**: Your microphone captures voice input
2. **ğŸ“Š Preprocessing**: Audio is cleaned and formatted (16kHz, mono)
3. **ğŸ”„ STT Processing**: 
   - **Premium Mode**: ElevenLabs Scribe (99 languages, word timestamps)
   - **Local Mode**: faster-whisper (multilingual, offline)
4. **ğŸ“ Text Output**: "Hello, how are you?" 
5. **ğŸ§  Language Detection**: Auto-detects English/French

---

### ğŸ§  **LLM Processing Pipeline**

```mermaid
flowchart LR
    A[ğŸ“ Input Text] --> B[ğŸ”„ Context Building]
    B --> C[ğŸ§  Ollama LLM]
    C --> D[âš¡ llama3.1:8b]
    D --> E[ğŸ¯ Response Generation]
    E --> F[ğŸ“¤ Output Text]
    
    style A fill:#e1f5fe
    style C fill:#f3e5f5
    style D fill:#e8f5e8
    style F fill:#fff3e0
```

**What happens:**
1. **ğŸ“ Input**: "Hello, how are you?"
2. **ğŸ”„ Context**: Conversation history + system prompts
3. **ğŸ§  LLM Processing**: 
   - **Model**: llama3.1:8b-instruct (8 billion parameters)
   - **Processing**: Local inference via Ollama
   - **Languages**: Bilingual EN/FR support
4. **ğŸ¯ Generation**: AI crafts contextual response
5. **ğŸ“¤ Output**: "I'm doing great! How can I help you today?"

---

### ğŸ”Š **Text-to-Speech (TTS) Pipeline**

```mermaid
flowchart TD
    A[ğŸ“¤ LLM Response] --> B[ğŸ”„ Text Processing]
    B --> C[ğŸ­ Voice Selection]
    C --> D{TTS Engine}
    D -->|Premium| E[ğŸ† ElevenLabs Flash]
    D -->|Local| F[âš¡ Kokoro/Piper]
    E --> G[ğŸµ Audio Generation]
    F --> G
    G --> H[ğŸ”Š Audio Output]
    H --> I[ğŸ“± Speaker/Headphones]
    
    style A fill:#e1f5fe
    style E fill:#f3e5f5
    style F fill:#e8f5e8
    style I fill:#fff3e0
```

**What happens:**
1. **ğŸ“¤ Text Input**: "I'm doing great! How can I help you today?"
2. **ğŸ”„ Processing**: Text cleanup, pronunciation optimization
3. **ğŸ­ Voice Selection**:
   - **English**: Rachel (clear, friendly)
   - **French**: Charlotte (native accent)
4. **ğŸµ Audio Generation**:
   - **Premium**: ElevenLabs `eleven_flash_v2_5` (75ms latency)
   - **Local**: Kokoro or Piper TTS
5. **ğŸ”Š Output**: High-quality MP3 audio
6. **ğŸ“± Playback**: Through your speakers/headphones

---

## ğŸ›ï¸ **Complete Voice Conversation Flow**

```mermaid
sequenceDiagram
    participant U as ğŸ¤ User
    participant STT as ğŸ“ Speech-to-Text
    participant LLM as ğŸ§  AI Brain
    participant TTS as ğŸ”Š Text-to-Speech
    participant S as ğŸ”Š Speaker
    
    U->>STT: "Bonjour, comment allez-vous?"
    STT->>STT: ğŸ”„ Audio â†’ Text conversion
    STT->>LLM: "Bonjour, comment allez-vous?"
    LLM->>LLM: ğŸ§  Process + Generate response
    LLM->>TTS: "Bonjour! Je vais trÃ¨s bien, merci!"
    TTS->>TTS: ğŸµ Text â†’ Audio conversion
    TTS->>S: ğŸ”Š Audio output
    S->>U: ğŸ§ "Bonjour! Je vais trÃ¨s bien, merci!"
    
    Note over U,S: Complete conversation cycle: ~2-3 seconds
```

---

## ğŸµ Audio Files & Testing

### Generated Audio Files
Your agent creates audio files you can play:

```bash
# Play generated audio samples
open voice_agent_test.mp3         # Latest TTS test
open conversation_1.mp3           # French learning demo
open env_test_output.mp3          # Environment test
```

### Audio Quality Comparison

| Mode | Engine | Quality | Latency | Cost | Languages |
|------|--------|---------|---------|------|-----------|
| ğŸ† **Premium** | ElevenLabs Flash | Excellent | 75ms | Pay-per-use | 32 |
| âš¡ **Local** | faster-whisper + Kokoro | Good | 200ms | Free | 16 |
| ğŸ”„ **Hybrid** | ElevenLabs TTS + Local STT | Best | 150ms | TTS only | 32 |

---

## ğŸŒ Supported Languages

### Primary Languages
- ğŸ‡ºğŸ‡¸ **English** - Native support, clear pronunciation
- ğŸ‡«ğŸ‡· **French** - Optimized for language learning

### Voice Presets
```bash
# English Voices
Rachel (EN-F) - Clear, friendly, professional
Adam (EN-M) - Deep, authoritative, warm

# French Voices  
Charlotte (FR-F) - Native French accent, educational
Antoine (FR-M) - Parisian accent, conversational
```

---

## ğŸ”§ Configuration

### Environment Variables
Your `.env` file controls everything:

```bash
# ğŸ”‘ ElevenLabs (Premium Audio)
ELEVENLABS_API_KEY=sk_your_key_here
ELEVENLABS_TTS_MODEL=eleven_flash_v2_5  # Cost-optimized
ELEVENLABS_STT_MODEL=scribe_v1          # 99 languages

# ğŸ§  LLM (Local AI)
LLM_MODEL=llama3.1:8b-instruct-q4_K_M  # Main model
LLM_FALLBACK=mistral:7b-instruct-q4_K_M # Backup

# ğŸ™ï¸ Audio Settings
SAMPLE_RATE=16000
CHANNELS=1
TTS_SPEED=1.0
```

### Cost Optimization
- **ElevenLabs TTS**: `eleven_flash_v2_5` (50% cheaper, 40K char limit)
- **Local STT**: faster-whisper (completely free)
- **Local LLM**: Ollama (completely free)
- **Result**: Premium audio quality at minimal cost! ğŸ’°

---

## ğŸ® Interactive Commands

### Development Commands
```bash
make help           # ğŸ“‹ Show all available commands
make setup          # ğŸ› ï¸ Install dependencies  
make clean          # ğŸ§¹ Clean cache and temp files
make test           # âœ… Run test suite
```

### Voice Agent Commands
```bash
make talk           # ğŸ’¬ Text chat mode
make run            # ğŸ™ï¸ Full voice agent
make test-elevenlabs # ğŸ§ª Test audio integration
```

### Docker & Models
```bash
make start-ollama   # ğŸ³ Start AI brain
make pull-model     # ğŸ“¥ Download LLM
make stop-ollama    # ğŸ›‘ Stop AI brain
```

---

## ğŸ—ï¸ Architecture

### System Components

```mermaid
graph TB
    subgraph "ğŸ¤ Audio Input"
        A[Microphone]
        B[WebRTC Stream]
    end
    
    subgraph "ğŸ§  Processing Core"
        C[LiveKit Agent]
        D[Speech Pipeline]
        E[LLM Engine]
    end
    
    subgraph "ğŸ”Š Audio Output"
        F[ElevenLabs TTS]
        G[Local TTS]
        H[Speaker Output]
    end
    
    A --> C
    B --> C
    C --> D
    D --> E
    E --> F
    E --> G
    F --> H
    G --> H
    
    style C fill:#e1f5fe
    style E fill:#f3e5f5
    style F fill:#e8f5e8
```

### Technology Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| ğŸ¤ **Audio I/O** | LiveKit WebRTC | Real-time audio streaming |
| ğŸ“ **STT** | faster-whisper / ElevenLabs | Speech recognition |
| ğŸ§  **AI** | Ollama + llama3.1 | Local language understanding |
| ğŸ”Š **TTS** | ElevenLabs Flash | Premium voice synthesis |
| ğŸŒ **Interface** | Python + AsyncIO | Real-time processing |
| ğŸ³ **Deployment** | Docker Compose | Container orchestration |

---

## ğŸŠ Fun Features

### ğŸ­ Voice Personalities
- **ğŸ‘©â€ğŸ« Teacher Mode**: Patient, educational responses
- **ğŸ¤– Assistant Mode**: Helpful, professional tone  
- **ğŸ’¬ Casual Mode**: Friendly, conversational style
- **ğŸ‡«ğŸ‡· French Tutor**: Specialized for language learning

### ğŸ® Interactive Elements
- **Real-time audio visualization** (coming soon)
- **Conversation history** with audio playback
- **Language switching** mid-conversation
- **Voice emotion detection** (experimental)

### ğŸ† Achievement System
- ğŸ¥‡ **First Conversation**: Complete your first voice chat
- ğŸ‡«ğŸ‡· **Polyglot**: Successfully switch between EN/FR
- ğŸ¤ **Voice Master**: Generate 10+ audio responses
- ğŸ¤– **AI Whisperer**: Have a 5+ turn conversation

---

## ğŸ” Troubleshooting

### Common Issues

| Issue | Solution | Command |
|-------|----------|---------|
| ğŸ³ Docker not running | Start Docker Desktop | `make start-ollama` |
| ğŸ”‘ API key invalid | Check ElevenLabs dashboard | `make test-elevenlabs` |
| ğŸ¤ No audio input | Check microphone permissions | Browser settings |
| ğŸ§  LLM not responding | Restart Ollama | `make stop-ollama && make start-ollama` |

### Debug Commands
```bash
make check-config   # ğŸ” Validate configuration
make test          # âœ… Run full test suite  
make clean         # ğŸ§¹ Reset everything
```

---

## ğŸ¯ Next Steps

1. **ğŸš€ Start Simple**: Try `make talk` for text chat
2. **ğŸª Explore Audio**: Run `voice_demo.py` for TTS testing  
3. **ğŸ™ï¸ Go Full Voice**: Use `make run` for complete experience
4. **ğŸ‡«ğŸ‡· Learn Languages**: Practice French conversation
5. **ğŸ› ï¸ Customize**: Modify voices, models, and responses

---

## ğŸ“¸ Screenshots & Demos

### Terminal Output Examples

**Voice Demo Menu:**
```
ğŸ™ï¸ ELEVENLABS VOICE AGENT DEMO
============================================================
Choose what you'd like to test:
1. ğŸ—£ï¸  Test TTS (Text-to-Speech)
2. ğŸ¤– Demo Conversation with Voice  
3. ğŸ“‹ Show Agent Capabilities
4. ğŸš€ All Tests
0. ğŸšª Exit
```

**Conversation Flow:**
```
ğŸ‘¤ You: Hello, can you help me practice French?
ğŸ¤– Agent: Bonjour! I'd be happy to help you practice French. 
          What would you like to work on today?
   ğŸ”Š Audio saved: conversation_1.mp3
```

---

<div align="center">

**ğŸ‰ Ready to chat with your AI voice agent? Pick a mode and start talking! ğŸ™ï¸**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ’¬ Text Mode](#2--text-chat-agent) â€¢ [ğŸ™ï¸ Voice Mode](#3--full-voice-agent-complete-experience) â€¢ [ğŸ§ª Test Audio](#4--elevenlabs-testing-suite)

---

*Built with â¤ï¸ using LiveKit, ElevenLabs, and Ollama*

</div>